<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>WAIveform | My Notebook</title><meta name=keywords content="Startup"><meta name=description content="Potential customer contacts Qualcomm Arash Behboodi (ai research) Dashan Gao (machine learning, ai) Tharak Krishnan (product and engineer leader) Yasutomo Matsuba (principle engineer video) Apple Said Medjkouh (RnD, wireless tech/ecosystem) Alan Carlton (wireless research) Kenza Hamidouche (wireless systems architect) Krisztian Kiss (senior wireless standards) Onur Sahin (wireless research) FB Joel Kyungho Kim (head of cellular tech) Jean-Yves Bouguet (head of ar/vr) BT Ed Hunter (Cellular for Drones & XCelerate Future Flight Project Manager) Intel Gila Kamhi (chief ai officer) Oner Orhan (AI/ML Research Scientist at Intel Labs) Jodie Frew (IoT, ai, business acceleration) Imagination Tim Atherton (director of ai) Arm Sofiane Yous (Senior Principal Embedded AI/ML) Funding tips Alexandria (Creator Fund) There are basically 3 stages between idea to series A:"><meta name=author content="Tze-Yang Tung"><link rel=canonical href=https://r0ymanesco.github.io/my-notes/posts/waiveform/><link crossorigin=anonymous href=/my-notes/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/my-notes/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://r0ymanesco.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://r0ymanesco.github.io/my-notes/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://r0ymanesco.github.io/my-notes/favicon-32x32.png><link rel=apple-touch-icon href=https://r0ymanesco.github.io/my-notes/apple-touch-icon.png><link rel=mask-icon href=https://r0ymanesco.github.io/my-notes/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})})</script><meta property="og:title" content="WAIveform"><meta property="og:description" content="Potential customer contacts Qualcomm Arash Behboodi (ai research) Dashan Gao (machine learning, ai) Tharak Krishnan (product and engineer leader) Yasutomo Matsuba (principle engineer video) Apple Said Medjkouh (RnD, wireless tech/ecosystem) Alan Carlton (wireless research) Kenza Hamidouche (wireless systems architect) Krisztian Kiss (senior wireless standards) Onur Sahin (wireless research) FB Joel Kyungho Kim (head of cellular tech) Jean-Yves Bouguet (head of ar/vr) BT Ed Hunter (Cellular for Drones & XCelerate Future Flight Project Manager) Intel Gila Kamhi (chief ai officer) Oner Orhan (AI/ML Research Scientist at Intel Labs) Jodie Frew (IoT, ai, business acceleration) Imagination Tim Atherton (director of ai) Arm Sofiane Yous (Senior Principal Embedded AI/ML) Funding tips Alexandria (Creator Fund) There are basically 3 stages between idea to series A:"><meta property="og:type" content="article"><meta property="og:url" content="https://r0ymanesco.github.io/my-notes/posts/waiveform/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-03T00:00:00+00:00"><meta property="article:modified_time" content="2023-03-07T16:53:16-05:00"><meta property="og:site_name" content="My Notebook"><meta name=twitter:card content="summary"><meta name=twitter:title content="WAIveform"><meta name=twitter:description content="Potential customer contacts Qualcomm Arash Behboodi (ai research) Dashan Gao (machine learning, ai) Tharak Krishnan (product and engineer leader) Yasutomo Matsuba (principle engineer video) Apple Said Medjkouh (RnD, wireless tech/ecosystem) Alan Carlton (wireless research) Kenza Hamidouche (wireless systems architect) Krisztian Kiss (senior wireless standards) Onur Sahin (wireless research) FB Joel Kyungho Kim (head of cellular tech) Jean-Yves Bouguet (head of ar/vr) BT Ed Hunter (Cellular for Drones & XCelerate Future Flight Project Manager) Intel Gila Kamhi (chief ai officer) Oner Orhan (AI/ML Research Scientist at Intel Labs) Jodie Frew (IoT, ai, business acceleration) Imagination Tim Atherton (director of ai) Arm Sofiane Yous (Senior Principal Embedded AI/ML) Funding tips Alexandria (Creator Fund) There are basically 3 stages between idea to series A:"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Topics","item":"https://r0ymanesco.github.io/my-notes/posts/"},{"@type":"ListItem","position":3,"name":"WAIveform","item":"https://r0ymanesco.github.io/my-notes/posts/waiveform/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"WAIveform","name":"WAIveform","description":"Potential customer contacts Qualcomm Arash Behboodi (ai research) Dashan Gao (machine learning, ai) Tharak Krishnan (product and engineer leader) Yasutomo Matsuba (principle engineer video) Apple Said Medjkouh (RnD, wireless tech/ecosystem) Alan Carlton (wireless research) Kenza Hamidouche (wireless systems architect) Krisztian Kiss (senior wireless standards) Onur Sahin (wireless research) FB Joel Kyungho Kim (head of cellular tech) Jean-Yves Bouguet (head of ar/vr) BT Ed Hunter (Cellular for Drones \u0026amp; XCelerate Future Flight Project Manager) Intel Gila Kamhi (chief ai officer) Oner Orhan (AI/ML Research Scientist at Intel Labs) Jodie Frew (IoT, ai, business acceleration) Imagination Tim Atherton (director of ai) Arm Sofiane Yous (Senior Principal Embedded AI/ML) Funding tips Alexandria (Creator Fund) There are basically 3 stages between idea to series A:","keywords":["Startup"],"articleBody":"Potential customer contacts Qualcomm Arash Behboodi (ai research) Dashan Gao (machine learning, ai) Tharak Krishnan (product and engineer leader) Yasutomo Matsuba (principle engineer video) Apple Said Medjkouh (RnD, wireless tech/ecosystem) Alan Carlton (wireless research) Kenza Hamidouche (wireless systems architect) Krisztian Kiss (senior wireless standards) Onur Sahin (wireless research) FB Joel Kyungho Kim (head of cellular tech) Jean-Yves Bouguet (head of ar/vr) BT Ed Hunter (Cellular for Drones \u0026 XCelerate Future Flight Project Manager) Intel Gila Kamhi (chief ai officer) Oner Orhan (AI/ML Research Scientist at Intel Labs) Jodie Frew (IoT, ai, business acceleration) Imagination Tim Atherton (director of ai) Arm Sofiane Yous (Senior Principal Embedded AI/ML) Funding tips Alexandria (Creator Fund) There are basically 3 stages between idea to series A:\nPre-seed Seed Series A In each round, expect to lose 15-25% of equity (25% is very bad). By the time you reach series A, you need to not only be making revenue (not necessarily profit), but also hold 50% of the company between the people that work at the company full time.\nThere are tax benefits in the UK for individuals that invest in startups ( SEIS , EIS ), which is why angel investors will do this rather than invest in other things (e.g., stocks). In other to be elegible for those UK tax benefits, you need to be an incorporated company.\nA good way to calculate the ownership ratio is to consider how many hours each founder spends on the company each week.\nTomas For pre-seed, we’ll want to establish a realistic problem and solution. We don’t need to generate any revenue, but the problem we want to solve should have both a financial and emotional pull. For example, making a smarthome work better doesn’t have a lot of emotional pull and might be harder to get funding compared to autonomous vehicle safety which is clearly a problem and lots of people will have known someone in a car accident. The market size and potential financial return for AVs is also much larger than smarthome devices. Even though AV space is much harder to enter, the potential for the market and our solution could lead to enough funding for entry.\nSmart home Challenges Security This is the same as Ana-Maria/Hamed’s startup. This is assumed to be handled in the application layer.\nConnectivity/reliability This is where we might be able to innovate. Typical smart home protocol uses 802.14.5 as the PHY standard. It doesn’t specify any channel codes, only a DSSS is used. If we can come up with a very simple channel code that can run in software, then this might improve the reliability of smart home devices. Any solution needs to be very easy to implement (no new hardware requirements).\nFrom looking at the Thread API, it seems that the main challenges worth addressing are:\nLow data rate, short range This is currently solved using a mesh network, which is a multi-hop problem. An implementation of channel coding could also help but would have to be extremely efficient. Recall the key to this space is energy efficiency. JSCC could certain help if we can treat the whole mesh as a single system and do some kind of task oriented coding.\nTopological reconfiguration after node dropout Thread implements self-healing, which is when a single device drops out of the mesh, it can reconfigure its topology without it. It is not clear yet whether this reconfiguration takes into account the network environment. If it doesn’t, this can have a big impact on performance if the topology can be reconfigured to ensure reliability/latency due to channel quality.\nBandwidth management This is due to the large number of devices that could be on the network. It is not clear how they are managing this either, possibly not a lot of optimization into this. This problem can be folded into the data rate/range problem.\nIn fact, these three problems can all be folded into one optimization problem. OpenThread also offers open source APIs to test new algorithms.\nMarket segmentation/interoperability Is it possible for someone to come up with a universal API for all smart home standards? I think this will be increasingly irrelevant as more manufacturers start using Thread.\nMultiple-access relay channel (MARC) A smarthome network is basically a mutiple-access relay channel (MARC).\nIntegrated sensing and communications (ISAC) ISAC for multiple access channels (MAC) is also amiable to JSCC. This is mostly due to the fact that MACs can gain more significantly than point-to-point.\nCustomer discovery Skydio The meeting verified our current solution cannot go to market but a discrete outter JSCC code using existing PHY implementation could. It also verified that targetting markets that have solutions that are very good already will not succeed. The issue is in order to just close the gap in hardware compared to existing implementations, the capital cost is already too high. We need to target problems that don’t have good solutions where the gains can be obtained without closing those gaps.\nAutonomous vehicles Safety Can we develop a inter-autonomous vehicle protocol so that we can improve the safety of AVs? The motivation is as follows:\nAVs are good for many general cases but fail at one in a million scenarios. With the help with other AVs, we can make a problem that happens in 1e-6 to 1e-9 for example. Moreover, the models deployed in each car might be easier to train since they no longer have to be reliable on their own, but rather, reliable in aggregate. An interesting idea that Tomas brought up is rather than trying to license this technology, we can instead form a network of cars ourselves and sell access to this network instead. Although it might seem difficult to build such network, comma.ai has demonstrated that it’s possible to start a company in this space if the technology is sufficiently good. We could even recruit Uber drivers and ask them to install an app on their phone that could build this network. The drivers could opt in to such schemes and get paid for sharing this data, we would get a cut of that money.\nCustomer discovery DIMO is a company that tries to something similar. The idea is that car owners record statistics about their car using the app and the company provides a service to them, such as insurance and resale value. They are also going to be opening up APIs to allow others to either:\nSell products to their customers directly (e.g., insurance) Use their data to perform some other purpose Build new hardware using their backend However, this is still more of a data aggregation service and all of the inference is done in a offline, non-real time sort of way. When asked whether he sees any real-time uses of this data, the co-founder Andy Chatham did not respond directly. He also mentioned that the major problems in the AV space is mostly infrastructure related and that he thinks only when these issues are resolved can you build more advanced experiences on top of that. Those issues include:\nHow to meet the charging demand since almost all AVs today are electric? How to store them and deploy them so that their up time is maximised? This is more about robotaxis, which he also thinks is the only viable market that will use AVs in the near future. We have also spoken to Markus Hantschmann from Roadia , a startup in Germany focusing on V2X for vehicle safety. There, their biggest challenge is to convince officials that their technology is worth pursuing. An important thing to keep in mind is who is benefiting? Politicians have very different incentive structures to corporations, so it’s important to keep that in mind when approaching them. Traffic management centres are also great sources of information, if you can get a hold of them. One thing that was quite interesting to hear is that, rather than deploying new hardware, cities actually already have lots of hardware installed, but no one to really aggregate that information. For example, traffic cameras, sensors, temperature readings…etc. A software solution utilising existing hardware would be much cheaper to show and officials would like that since it doesn’t involve spending more public money. It may also shorten the time to deployment since working with the government always involves a lengthy process to secure funding and permission…etc. However, in general, this type of work is better done in Europe because the government is more centralised. London for example has city labs, which is a testbed for V2X ideas.\nGenerative models Safety/Accuracy Following the same line of thinking for AVs, monolithic LLMs have shown tremendous progress but it’s also clear that they lack safety features that prevent them from outputting text that may be harmful. That includes racist content as well as falsehoods that are presented confidently. Google has been thinking about this quite a bit clearly, since this is directly going to affect their most important product. DeepMind also submitted a benchmark paper to NeurIPS last year that tries to quantify harmful output of a LLM. But I think this is still a huge open question that needs addressing ASAP and similar to the idea we have about AVs, perhaps the onous should not be on individual models but rather the output of LLMs should be fact-checked by querying multiple sources. Similar to how humans research, LLMs should also check sources other than itself. This may not completely rid LLMs from outputting incorrect things, as a human cannot always get everything correct, but it will surely improve the reliability. From the perspective of machine-to-machine communication, think of this as LLMs talking to other computing platforms, whether that is Wikipedia or literally writing an email to a professor somewhere to ask for an opinion. This might be the missing ingredient to making these models, which are increasingly affecting our daily lives, more trustworthy.\nThis idea is certainly not limited to LLMs, as diffusion models also have a similar issue, where it can be misappropriated to output images that are inappropriate or illegal. Moreover, there is increasingly concerns that it violates the copyright of other people’s work. If it can check that someone has copyrighted something extremely similar to its output, then it might choose to output something else that is sufficiently different.\nAggregation There are increasingly generative AI tools that are open to access by regular users. But not everyone knows how to use it or that they even exist. Can we have a common interfact, similar to Google search where depending on what kind of result you want (text, images…), you can select the relevant “tab” and use a generative AI tool to get a result? Moreover, can we create a single search box, which breaks down a search query into multiple queries and sends them to the relevant models? This might even be achievable with prompt engineering, designing inputs that help us get the output we want. The could create a much richer search experience, multi-modal and more informative. It would certainly compliment the safety angle .\n","wordCount":"1840","inLanguage":"en","datePublished":"2023-01-03T00:00:00Z","dateModified":"2023-03-07T16:53:16-05:00","author":[{"@type":"Person","name":"Tze-Yang Tung"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://r0ymanesco.github.io/my-notes/posts/waiveform/"},"publisher":{"@type":"Organization","name":"My Notebook","logo":{"@type":"ImageObject","url":"https://r0ymanesco.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://r0ymanesco.github.io/my-notes accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://r0ymanesco.github.io/my-notes/posts/ title=Topics><span>Topics</span></a></li><li><a href=https://r0ymanesco.github.io/my-notes/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://r0ymanesco.github.io/my-notes/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://r0ymanesco.github.io/my-notes/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://r0ymanesco.github.io/my-notes/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://r0ymanesco.github.io/my-notes>Home</a>&nbsp;»&nbsp;<a href=https://r0ymanesco.github.io/my-notes/posts/>Topics</a></div><h1 class=post-title>WAIveform</h1><div class=post-meta><span title='2023-01-03 00:00:00 +0000 UTC'>3 January, 2023</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1840 words&nbsp;·&nbsp;Tze-Yang Tung</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#waiveform_a>Potential customer contacts</a><ul><li><a href=#waiveform_a1>Qualcomm</a></li><li><a href=#waiveform_a2>Apple</a></li><li><a href=#waiveform_a3>FB</a></li><li><a href=#waiveform_a4>BT</a></li><li><a href=#waiveform_a5>Intel</a></li><li><a href=#waiveform_a6>Imagination</a></li><li><a href=#waiveform_a7>Arm</a></li></ul></li><li><a href=#waiveform_b>Funding tips</a><ul><li><a href=#waiveform_b1>Alexandria (Creator Fund)</a></li><li><a href=#waiveform_b2>Tomas</a></li></ul></li><li><a href=#waiveform_c>Smart home</a><ul><li><a href=#waiveform_c1>Challenges</a></li><li><a href=#waiveform_c2>Multiple-access relay channel (MARC)</a></li><li><a href=#waiveform_c3>Integrated sensing and communications (ISAC)</a></li><li><a href=#waiveform_c4>Customer discovery</a></li></ul></li><li><a href=#waiveform_d>Autonomous vehicles</a><ul><li><a href=#waiveform_d1>Safety</a></li><li><a href=#waiveform_d2>Customer discovery</a></li></ul></li><li><a href=#waiveform_e>Generative models</a><ul><li><a href=#waiveform_e1>Safety/Accuracy</a></li><li><a href=#waiveform_e2>Aggregation</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=waiveform_a>Potential customer contacts<a hidden class=anchor aria-hidden=true href=#waiveform_a>#</a></h2><h3 id=waiveform_a1>Qualcomm<a hidden class=anchor aria-hidden=true href=#waiveform_a1>#</a></h3><ul><li>Arash Behboodi (ai research)</li><li>Dashan Gao (machine learning, ai)</li><li>Tharak Krishnan (product and engineer leader)</li><li>Yasutomo Matsuba (principle engineer video)</li></ul><h3 id=waiveform_a2>Apple<a hidden class=anchor aria-hidden=true href=#waiveform_a2>#</a></h3><ul><li>Said Medjkouh (RnD, wireless tech/ecosystem)</li><li>Alan Carlton (wireless research)</li><li>Kenza Hamidouche (wireless systems architect)</li><li>Krisztian Kiss (senior wireless standards)</li><li>Onur Sahin (wireless research)</li></ul><h3 id=waiveform_a3>FB<a hidden class=anchor aria-hidden=true href=#waiveform_a3>#</a></h3><ul><li>Joel Kyungho Kim (head of cellular tech)</li><li>Jean-Yves Bouguet (head of ar/vr)</li></ul><h3 id=waiveform_a4>BT<a hidden class=anchor aria-hidden=true href=#waiveform_a4>#</a></h3><ul><li>Ed Hunter (Cellular for Drones & XCelerate Future Flight Project Manager)</li></ul><h3 id=waiveform_a5>Intel<a hidden class=anchor aria-hidden=true href=#waiveform_a5>#</a></h3><ul><li>Gila Kamhi (chief ai officer)</li><li>Oner Orhan (AI/ML Research Scientist at Intel Labs)</li><li>Jodie Frew (IoT, ai, business acceleration)</li></ul><h3 id=waiveform_a6>Imagination<a hidden class=anchor aria-hidden=true href=#waiveform_a6>#</a></h3><ul><li>Tim Atherton (director of ai)</li></ul><h3 id=waiveform_a7>Arm<a hidden class=anchor aria-hidden=true href=#waiveform_a7>#</a></h3><ul><li>Sofiane Yous (Senior Principal Embedded AI/ML)</li></ul><h2 id=waiveform_b>Funding tips<a hidden class=anchor aria-hidden=true href=#waiveform_b>#</a></h2><h3 id=waiveform_b1>Alexandria (Creator Fund)<a hidden class=anchor aria-hidden=true href=#waiveform_b1>#</a></h3><p>There are basically 3 stages between idea to series A:</p><ul><li>Pre-seed</li><li>Seed</li><li>Series A</li></ul><p>In each round, expect to lose 15-25% of equity (25% is very bad).
By the time you reach series A, you need to not only be making revenue (not necessarily profit), but also hold 50% of the company between the people that work at the company full time.</p><p>There are tax benefits in the UK for individuals that invest in startups (<a href=https://www.gov.uk/guidance/venture-capital-schemes-apply-to-use-the-seed-enterprise-investment-scheme target=_blank>
SEIS</a>
, <a href=https://www.gov.uk/guidance/venture-capital-schemes-apply-for-the-enterprise-investment-scheme#how-the-scheme-works target=_blank>EIS</a>
), which is why angel investors will do this rather than invest in other things (e.g., stocks).
In other to be elegible for those UK tax benefits, you need to be an incorporated company.</p><p>A good way to calculate the ownership ratio is to consider how many hours each founder spends on the company each week.</p><h3 id=waiveform_b2>Tomas<a hidden class=anchor aria-hidden=true href=#waiveform_b2>#</a></h3><p>For pre-seed, we&rsquo;ll want to establish a realistic problem and solution.
We don&rsquo;t need to generate any revenue, but the problem we want to solve should have both a financial and <strong>emotional</strong> pull.
For example, making a smarthome work better doesn&rsquo;t have a lot of emotional pull and might be harder to get funding compared to autonomous vehicle safety which is clearly a problem and lots of people will have known someone in a car accident.
The market size and potential financial return for AVs is also much larger than smarthome devices.
Even though AV space is much harder to enter, the potential for the market and our solution could lead to enough funding for entry.</p><h2 id=waiveform_c>Smart home<a hidden class=anchor aria-hidden=true href=#waiveform_c>#</a></h2><h3 id=waiveform_c1>Challenges<a hidden class=anchor aria-hidden=true href=#waiveform_c1>#</a></h3><h4 id=projects_c1a>Security<a hidden class=anchor aria-hidden=true href=#projects_c1a>#</a></h4><p>This is the same as Ana-Maria/Hamed&rsquo;s startup.
This is assumed to be handled in the application layer.</p><h4 id=waiveform_c1b>Connectivity/reliability<a hidden class=anchor aria-hidden=true href=#waiveform_c1b>#</a></h4><p>This is where we might be able to innovate.
Typical smart home protocol uses 802.14.5 as the PHY standard.
It doesn&rsquo;t specify any channel codes, only a DSSS is used.
If we can come up with a very simple channel code that can run in software,
then this might improve the reliability of smart home devices.
Any solution needs to be very easy to implement (no new hardware requirements).</p><p>From looking at the Thread API, it seems that the main challenges worth addressing are:</p><ul><li>Low data rate, short range</li></ul><p>This is currently solved using a mesh network, which is a <strong>multi-hop</strong> problem.
An implementation of channel coding could also help but would have to be extremely efficient. Recall the key to this space is energy efficiency.
JSCC could certain help if we can treat the whole mesh as a single system and do some kind of task oriented coding.</p><ul><li>Topological reconfiguration after node dropout</li></ul><p>Thread implements self-healing, which is when a single device drops out of the mesh, it can reconfigure its topology without it.
It is not clear yet whether this reconfiguration takes into account the network environment.
If it doesn&rsquo;t, this can have a big impact on performance if the topology can be reconfigured to ensure reliability/latency due to channel quality.</p><ul><li>Bandwidth management</li></ul><p>This is due to the large number of devices that could be on the network.
It is not clear how they are managing this either, possibly not a lot of optimization into this.
This problem can be folded into the data rate/range problem.</p><p>In fact, these three problems can all be folded into one optimization problem.
<a href=https://openthread.io/guides/thread-primer/ target=_blank>OpenThread</a>
also offers open source APIs to test new algorithms.</p><h4 id=waiveform_c1c>Market segmentation/interoperability<a hidden class=anchor aria-hidden=true href=#waiveform_c1c>#</a></h4><p>Is it possible for someone to come up with a universal API for all smart home standards?
I think this will be increasingly irrelevant as more manufacturers start using Thread.</p><h3 id=waiveform_c2>Multiple-access relay channel (MARC)<a hidden class=anchor aria-hidden=true href=#waiveform_c2>#</a></h3><p>A smarthome network is basically a mutiple-access relay channel (MARC).</p><h3 id=waiveform_c3>Integrated sensing and communications (ISAC)<a hidden class=anchor aria-hidden=true href=#waiveform_c3>#</a></h3><p>ISAC for multiple access channels (MAC) is also amiable to JSCC.
This is mostly due to the fact that MACs can gain more significantly than point-to-point.</p><h3 id=waiveform_c4>Customer discovery<a hidden class=anchor aria-hidden=true href=#waiveform_c4>#</a></h3><h4 id=waiveform_c4a>Skydio<a hidden class=anchor aria-hidden=true href=#waiveform_c4a>#</a></h4><p>The meeting verified our current solution cannot go to market but a discrete outter JSCC code using existing PHY implementation could.
It also verified that targetting markets that have solutions that are very good already will not succeed.
The issue is in order to just close the gap in hardware compared to existing implementations, the capital cost is already too high.
We need to target problems that don&rsquo;t have good solutions where the gains can be obtained without closing those gaps.</p><h2 id=waiveform_d>Autonomous vehicles<a hidden class=anchor aria-hidden=true href=#waiveform_d>#</a></h2><h3 id=waiveform_d1>Safety<a hidden class=anchor aria-hidden=true href=#waiveform_d1>#</a></h3><p>Can we develop a inter-autonomous vehicle protocol so that we can improve the safety of AVs?
The motivation is as follows:</p><ul><li>AVs are good for many general cases but fail at one in a million scenarios.
With the help with other AVs, we can make a problem that happens in 1e-6 to 1e-9 for example.</li><li>Moreover, the models deployed in each car might be easier to train since they no longer have to be reliable on their own, but rather, reliable in aggregate.</li></ul><p>An interesting idea that Tomas brought up is rather than trying to license this technology, we can instead form a network of cars ourselves and sell <strong>access</strong> to this network instead.
Although it might seem difficult to build such network, <a href=https://comma.ai/ target=_blank>comma.ai</a>
has demonstrated that it&rsquo;s possible to start a company in this space if the technology is sufficiently good.
We could even recruit Uber drivers and ask them to install an app on their phone that could build this network.
The drivers could opt in to such schemes and get paid for sharing this data, we would get a cut of that money.</p><h3 id=waiveform_d2>Customer discovery<a hidden class=anchor aria-hidden=true href=#waiveform_d2>#</a></h3><p><a href=https://dimo.zone/ target=_blank>DIMO</a>
is a company that tries to something similar.
The idea is that car owners record statistics about their car using the app and the company provides a service to them, such as insurance and resale value.
They are also going to be opening up APIs to allow others to either:</p><ol><li>Sell products to their customers directly (e.g., insurance)</li><li>Use their data to perform some other purpose</li><li>Build new hardware using their backend</li></ol><p>However, this is still more of a data aggregation service and all of the inference is done in a offline, non-real time sort of way.
When asked whether he sees any real-time uses of this data, the co-founder Andy Chatham did not respond directly.
He also mentioned that the major problems in the AV space is mostly infrastructure related and that he thinks only when these issues are resolved can you build more advanced experiences on top of that.
Those issues include:</p><ul><li>How to meet the charging demand since almost all AVs today are electric?</li><li>How to store them and deploy them so that their up time is maximised?<ul><li>This is more about robotaxis, which he also thinks is the only viable market that will use AVs in the near future.</li></ul></li></ul><p>We have also spoken to Markus Hantschmann from <a href=https://www.roadia.com/en/home target=_blank>Roadia</a>
, a startup in Germany focusing on V2X for vehicle safety.
There, their biggest challenge is to convince officials that their technology is worth pursuing.
An important thing to keep in mind is <strong>who is benefiting</strong>?
Politicians have very different incentive structures to corporations, so it&rsquo;s important to keep that in mind when approaching them.
Traffic management centres are also great sources of information, if you can get a hold of them.
One thing that was quite interesting to hear is that, rather than deploying new hardware, cities actually already have lots of hardware installed, but no one to really aggregate that information.
For example, traffic cameras, sensors, temperature readings&mldr;etc.
A software solution utilising existing hardware would be much cheaper to show and officials would like that since it doesn&rsquo;t involve spending more public money.
It may also shorten the time to deployment since working with the government always involves a lengthy process to secure funding and permission&mldr;etc.
However, in general, this type of work is better done in Europe because the government is more centralised.
London for example has city labs, which is a testbed for V2X ideas.</p><h2 id=waiveform_e>Generative models<a hidden class=anchor aria-hidden=true href=#waiveform_e>#</a></h2><h3 id=waiveform_e1>Safety/Accuracy<a hidden class=anchor aria-hidden=true href=#waiveform_e1>#</a></h3><p>Following the same line of thinking for AVs, monolithic LLMs have shown tremendous progress but it&rsquo;s also clear that they lack safety features that prevent them from outputting text that may be harmful.
That includes racist content as well as falsehoods that are presented confidently.
<a href=https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html target=_blank>Google</a>
has been thinking about this quite a bit clearly, since this is directly going to affect their most important product.
<a href=https://www.deepmind.com/publications/characteristics-of-harmful-text-towards-rigorous-benchmarking-of-language-models target=_blank>DeepMind</a>
also submitted a benchmark paper to NeurIPS last year that tries to quantify harmful output of a LLM.
But I think this is still a huge open question that needs addressing ASAP and similar to the idea we have about AVs, perhaps the onous should not be on individual models but rather the output of LLMs should be fact-checked by querying multiple sources.
Similar to how humans research, LLMs should also check sources other than itself.
This may not completely rid LLMs from outputting incorrect things, as a human cannot always get everything correct, but it will surely improve the reliability.
From the perspective of machine-to-machine communication, think of this as LLMs talking to other computing platforms, whether that is Wikipedia or literally writing an email to a professor somewhere to ask for an opinion.
This might be the missing ingredient to making these models, which are increasingly affecting our daily lives, more trustworthy.</p><p>This idea is certainly not limited to LLMs, as diffusion models also have a similar issue, where it can be misappropriated to output images that are inappropriate or illegal.
Moreover, there is increasingly concerns that it violates the copyright of other people&rsquo;s work.
If it can check that someone has copyrighted something extremely similar to its output, then it might choose to output something else that is sufficiently different.</p><h3 id=waiveform_e2>Aggregation<a hidden class=anchor aria-hidden=true href=#waiveform_e2>#</a></h3><p>There are increasingly generative AI tools that are open to access by regular users.
But not everyone knows how to use it or that they even exist.
Can we have a common interfact, similar to Google search where depending on what kind of result you want (text, images&mldr;), you can select the relevant &ldquo;tab&rdquo; and use a generative AI tool to get a result?
Moreover, can we create a single search box, which breaks down a search query into multiple queries and sends them to the relevant models?
This might even be achievable with prompt engineering, designing inputs that help us get the output we want.
The could create a much richer search experience, multi-modal and more informative.
It would certainly compliment the <a href=#waiveform_e1>safety angle</a>
.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://r0ymanesco.github.io/my-notes/tags/startup/>Startup</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://r0ymanesco.github.io/my-notes>My Notebook</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>